<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 20 Exercise 4: Scaling techniques | Computational Text Analysis</title>
<meta name="author" content="Christopher Barrie">
<meta name="description" content="20.1 Introduction The hands-on exercise for this week focuses on: 1) scaling texts ; 2) implementing scaling techniques using quanteda. In this tutorial, you will learn how to: Scale texts using...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 20 Exercise 4: Scaling techniques | Computational Text Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://cjbarrie.github.io/CTA-ED/exercise-4-scaling-techniques.html">
<meta property="og:image" content="https://cjbarrie.github.io/CTA-ED/coverb.png">
<meta property="og:description" content="20.1 Introduction The hands-on exercise for this week focuses on: 1) scaling texts ; 2) implementing scaling techniques using quanteda. In this tutorial, you will learn how to: Scale texts using...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 20 Exercise 4: Scaling techniques | Computational Text Analysis">
<meta name="twitter:description" content="20.1 Introduction The hands-on exercise for this week focuses on: 1) scaling texts ; 2) implementing scaling techniques using quanteda. In this tutorial, you will learn how to: Scale texts using...">
<meta name="twitter:image" content="https://cjbarrie.github.io/CTA-ED/coverb.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Computational Text Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">‚ÄúComputational Text Analysis‚Äù (PGSP11584)</a></li>
<li><a class="" href="course-overview.html">Course Overview</a></li>
<li><a class="" href="introduction-to-r.html">Introduction to R</a></li>
<li><a class="" href="week-1-retrieving-and-analyzing-text.html"><span class="header-section-number">1</span> Week 1: Retrieving and analyzing text</a></li>
<li><a class="" href="week-2-tokenization-and-word-frequencies.html"><span class="header-section-number">2</span> Week 2: Tokenization and word frequencies</a></li>
<li><a class="" href="week-2-demo.html"><span class="header-section-number">3</span> Week 2 Demo</a></li>
<li><a class="" href="week-3-dictionary-based-techniques.html"><span class="header-section-number">4</span> Week 3: Dictionary-based techniques</a></li>
<li><a class="" href="week-3-demo.html"><span class="header-section-number">5</span> Week 3 Demo</a></li>
<li><a class="" href="week-4-natural-language-complexity-and-similarity.html"><span class="header-section-number">6</span> Week 4: Natural language, complexity, and similarity</a></li>
<li><a class="" href="week-4-demo.html"><span class="header-section-number">7</span> Week 4 Demo</a></li>
<li><a class="" href="week-5-scaling-techniques.html"><span class="header-section-number">8</span> Week 5: Scaling techniques</a></li>
<li><a class="" href="week-5-demo.html"><span class="header-section-number">9</span> Week 5 Demo</a></li>
<li><a class="" href="week-6-unsupervised-learning-topic-models.html"><span class="header-section-number">10</span> Week 6: Unsupervised learning (topic models)</a></li>
<li><a class="" href="week-6-demo.html"><span class="header-section-number">11</span> Week 6 Demo</a></li>
<li><a class="" href="week-7-unsupervised-learning-word-embedding.html"><span class="header-section-number">12</span> Week 7: Unsupervised learning (word embedding)</a></li>
<li><a class="" href="week-7-demo.html"><span class="header-section-number">13</span> Week 7 Demo</a></li>
<li><a class="" href="week-8-sampling-text-information.html"><span class="header-section-number">14</span> Week 8: Sampling text information</a></li>
<li><a class="" href="week-9-supervised-learning.html"><span class="header-section-number">15</span> Week 9: Supervised learning</a></li>
<li><a class="" href="week-10-validation.html"><span class="header-section-number">16</span> Week 10: Validation</a></li>
<li><a class="" href="exercise-1-word-frequency-analysis.html"><span class="header-section-number">17</span> Exercise 1: Word frequency analysis</a></li>
<li><a class="" href="exercise-2-dictionary-based-methods.html"><span class="header-section-number">18</span> Exercise 2: Dictionary-based methods</a></li>
<li><a class="" href="exercise-3-comparison-and-complexity.html"><span class="header-section-number">19</span> Exercise 3: Comparison and complexity</a></li>
<li><a class="active" href="exercise-4-scaling-techniques.html"><span class="header-section-number">20</span> Exercise 4: Scaling techniques</a></li>
<li><a class="" href="exercise-5-unsupervised-learning-topic-models.html"><span class="header-section-number">21</span> Exercise 5: Unsupervised learning (topic models)</a></li>
<li><a class="" href="exercise-6-unsupervised-learning-word-embedding.html"><span class="header-section-number">22</span> Exercise 6: Unsupervised learning (word embedding)</a></li>
<li><a class="" href="exercise-7-sampling-text-information.html"><span class="header-section-number">23</span> Exercise 7: Sampling text information</a></li>
<li><a class="" href="exercise-9-validation.html"><span class="header-section-number">24</span> Exercise 9: Validation</a></li>
<li><a class="" href="assessment-data.html"><span class="header-section-number">25</span> Assessment data</a></li>
<li><a class="" href="references-2.html"><span class="header-section-number">26</span> References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/cjbarrie/CTA-ED">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="exercise-4-scaling-techniques" class="section level1" number="20">
<h1>
<span class="header-section-number">20</span> Exercise 4: Scaling techniques<a class="anchor" aria-label="anchor" href="#exercise-4-scaling-techniques"><i class="fas fa-link"></i></a>
</h1>
<div id="introduction-3" class="section level2" number="20.1">
<h2>
<span class="header-section-number">20.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-3"><i class="fas fa-link"></i></a>
</h2>
<p>The hands-on exercise for this week focuses on: 1) scaling texts ; 2) implementing scaling techniques using <code>quanteda</code>.</p>
<p>In this tutorial, you will learn how to:</p>
<ul>
<li>Scale texts using the ‚Äúwordfish‚Äù algorithm</li>
<li>Scale texts gathered from online sources</li>
<li>Replicate analyses by <span class="citation">Kaneko, Asano, and Miwa (<a href="references-2.html#ref-kaneko_estimating_2021" role="doc-biblioref">2021</a>)</span>
</li>
</ul>
<p>Before proceeding, we‚Äôll load the packages we will need for this tutorial.</p>
<div class="sourceCode" id="cb297"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://quanteda.io">quanteda</a></span><span class="op">)</span> <span class="co"># includes functions to implement Lexicoder</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/quanteda/quanteda.textmodels">quanteda.textmodels</a></span><span class="op">)</span> <span class="co"># for estimating similarity and complexity measures</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">quanteda.textplots</span><span class="op">)</span> <span class="co">#for visualizing text modelling results</span></code></pre></div>
<p>In this exercise we‚Äôll be using the dataset we used for the sentiment analysis exercise. The data were collected from the Twitter accounts of the top eight newspapers in the UK by circulation. The tweets include any tweets by the news outlet from their main account.</p>
</div>
<div id="importing-data" class="section level2" number="20.2">
<h2>
<span class="header-section-number">20.2</span> Importing data<a class="anchor" aria-label="anchor" href="#importing-data"><i class="fas fa-link"></i></a>
</h2>
<p>We can download the dataset with:</p>
<div class="sourceCode" id="cb298"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tweets</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/readRDS.html">readRDS</a></span><span class="op">(</span><span class="st">"data/sentanalysis/newstweets.rds"</span><span class="op">)</span></code></pre></div>
<p>If you‚Äôre working on this document from your own computer (‚Äúlocally‚Äù) you can download the tweets data in the following way:</p>
<div class="sourceCode" id="cb299"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tweets</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/readRDS.html">readRDS</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/gzcon.html">gzcon</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/connections.html">url</a></span><span class="op">(</span><span class="st">"https://github.com/cjbarrie/CTA-ED/blob/main/data/sentanalysis/newstweets.rds?raw=true"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>We first take a sample from these data to speed up the runtime of some of the analyses.</p>
<div class="sourceCode" id="cb300"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tweets</span> <span class="op">&lt;-</span> <span class="va">tweets</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/sample_n.html">sample_n</a></span><span class="op">(</span><span class="fl">20000</span><span class="op">)</span></code></pre></div>
</div>
<div id="construct-dfm-object" class="section level2" number="20.3">
<h2>
<span class="header-section-number">20.3</span> Construct <code>dfm</code> object<a class="anchor" aria-label="anchor" href="#construct-dfm-object"><i class="fas fa-link"></i></a>
</h2>
<p>Then, as in the previous exercise, we create a corpus object, specify the document-level variables by which we want to group, and generate our document feature matrix.</p>
<div class="sourceCode" id="cb301"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#make corpus object, specifying tweet as text field</span>
<span class="va">tweets_corpus</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/corpus.html">corpus</a></span><span class="op">(</span><span class="va">tweets</span>, text_field <span class="op">=</span> <span class="st">"text"</span><span class="op">)</span>

<span class="co">#add in username document-level information</span>
<span class="fu"><a href="https://quanteda.io/reference/docvars.html">docvars</a></span><span class="op">(</span><span class="va">tweets_corpus</span>, <span class="st">"newspaper"</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">tweets</span><span class="op">$</span><span class="va">user_username</span>

<span class="va">dfm_tweets</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/dfm.html">dfm</a></span><span class="op">(</span><span class="fu"><a href="https://quanteda.io/reference/tokens.html">tokens</a></span><span class="op">(</span><span class="va">tweets_corpus</span><span class="op">)</span>,
                  remove_punct <span class="op">=</span> <span class="cn">TRUE</span>, 
                  remove <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/stopwords/man/stopwords.html">stopwords</a></span><span class="op">(</span><span class="st">"english"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>We can then have a look at the number of documents (tweets) we have per newspaper Twitter account.</p>
<div class="sourceCode" id="cb302"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">## number of tweets per newspaper</span>
<span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="fu"><a href="https://quanteda.io/reference/docvars.html">docvars</a></span><span class="op">(</span><span class="va">dfm_tweets</span>, <span class="st">"newspaper"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## 
##     DailyMailUK     DailyMirror EveningStandard        guardian         MetroUK       Telegraph 
##            2052            5834            2182            2939             966            1519 
##          TheSun        thetimes 
##            3840             668</code></pre>
<p>And this is what our document feature matrix looks like, where each word has a count for each of our eight newspapers.</p>
<div class="sourceCode" id="cb304"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">dfm_tweets</span></code></pre></div>
<pre><code>## Document-feature matrix of: 20,000 documents, 48,967 features (99.98% sparse) and 31 docvars.
##        features
## docs    rt @standardnews breaking coronavirus outbreak declared pandemic world health organisation
##   text1  1             1        1           1        1        1        1     1      1            1
##   text2  1             0        0           0        0        0        0     0      0            0
##   text3  0             0        0           0        0        0        0     0      0            0
##   text4  0             0        0           0        0        0        0     0      0            0
##   text5  0             0        0           0        0        0        0     0      0            0
##   text6  0             0        0           0        0        0        0     0      0            0
## [ reached max_ndoc ... 19,994 more documents, reached max_nfeat ... 48,957 more features ]</code></pre>
</div>
<div id="estimate-wordfish-model" class="section level2" number="20.4">
<h2>
<span class="header-section-number">20.4</span> Estimate wordfish model<a class="anchor" aria-label="anchor" href="#estimate-wordfish-model"><i class="fas fa-link"></i></a>
</h2>
<p>Once we have our data in this format, we are able to group and trim the document feature matrix before estimating the wordfish model.</p>
<div class="sourceCode" id="cb306"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># compress the document-feature matrix at the newspaper level</span>
<span class="va">dfm_newstweets</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/dfm_group.html">dfm_group</a></span><span class="op">(</span><span class="va">dfm_tweets</span>, groups <span class="op">=</span> <span class="va">newspaper</span><span class="op">)</span>
<span class="co"># remove words not used by two or more newspapers</span>
<span class="va">dfm_newstweets</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/dfm_trim.html">dfm_trim</a></span><span class="op">(</span><span class="va">dfm_newstweets</span>, 
                                min_docfreq <span class="op">=</span> <span class="fl">2</span>, docfreq_type <span class="op">=</span> <span class="st">"count"</span><span class="op">)</span>

<span class="co">## size of the document-feature matrix</span>
<span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">dfm_newstweets</span><span class="op">)</span></code></pre></div>
<pre><code>## [1]     8 11111</code></pre>
<div class="sourceCode" id="cb308"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">#### estimate the Wordfish model ####</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123L</span><span class="op">)</span>
<span class="va">dfm_newstweets_results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/quanteda.textmodels/man/textmodel_wordfish.html">textmodel_wordfish</a></span><span class="op">(</span><span class="va">dfm_newstweets</span>, 
                                             sparse <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<p>And this is what results.</p>
<div class="sourceCode" id="cb309"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">dfm_newstweets_results</span><span class="op">)</span></code></pre></div>
<pre><code>## 
## Call:
## textmodel_wordfish.dfm(x = dfm_newstweets, sparse = TRUE)
## 
## Estimated Document Positions:
##                    theta       se
## DailyMailUK      0.64904 0.012949
## DailyMirror      1.18235 0.006726
## EveningStandard -0.22616 0.016082
## guardian        -0.95428 0.010563
## MetroUK         -0.04625 0.022759
## Telegraph       -1.05344 0.010640
## TheSun           1.45044 0.006048
## thetimes        -1.00168 0.014966
## 
## Estimated Feature Scores:
##         rt breaking coronavirus outbreak declared pandemic  world  health organisation genuinely
## beta 0.537    0.191     0.06917  -0.2654 -0.06526  -0.2004 -0.317 -0.3277      -0.4118   -0.2873
## psi  5.307    3.535     5.78715   3.1348  0.50705   3.1738  3.366  3.2041       0.5487   -0.5403
##      interested       see      one     cos     fair  german    care system protect troubled
## beta    -0.2546 0.0005085 -0.06313 -0.2788 -0.03078 -0.7424 -0.3251 -1.105 -0.1106  -0.4731
## psi     -1.4502 2.7723965  3.85881 -1.4480  0.35480  1.1009  3.1042  1.259  1.8918  -0.0784
##      children #covid19 anxiety  shows    sign    man  behind   app explains    tips
## beta  0.01204  -0.6742  0.4218 0.4165 -0.1215 0.5112 0.05498 0.271   0.6687 -0.2083
## psi   2.85004   2.9703  0.5917 2.8370  1.9427 3.5777 2.43805 1.376   1.2749  1.5341</code></pre>
<p>We can then plot our estimates of the <span class="math inline">\(\theta\)</span>s‚Äîi.e., the estimates of the latent newspaper position‚Äîas so.</p>
<div class="sourceCode" id="cb311"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/pkg/quanteda.textplots/man/textplot_scale1d.html">textplot_scale1d</a></span><span class="op">(</span><span class="va">dfm_newstweets_results</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="main_files/figure-html/unnamed-chunk-172-1.png" width="672"></div>
<p>Interestingly, we seem not to have captured ideology but some other tonal dimension. We see that the tabloid newspapers are scored similarly, and grouped toward the right hand side of this latent dimension; whereas the broadsheet newspapers have an estimated theta further to the left.</p>
<p>Plotting the ‚Äúfeatures,‚Äù i.e., the word-level betas shows how words are positioned along this dimension, and which words help discriminate between news outlets.</p>
<div class="sourceCode" id="cb312"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/pkg/quanteda.textplots/man/textplot_scale1d.html">textplot_scale1d</a></span><span class="op">(</span><span class="va">dfm_newstweets_results</span>, margin <span class="op">=</span> <span class="st">"features"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="main_files/figure-html/unnamed-chunk-173-1.png" width="672"></div>
<p>And we can also look at these features.</p>
<div class="sourceCode" id="cb313"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">features</span> <span class="op">&lt;-</span> <span class="va">dfm_newstweets_results</span><span class="op">[[</span><span class="st">"features"</span><span class="op">]</span><span class="op">]</span>

<span class="va">betas</span> <span class="op">&lt;-</span> <span class="va">dfm_newstweets_results</span><span class="op">[[</span><span class="st">"beta"</span><span class="op">]</span><span class="op">]</span>

<span class="va">feat_betas</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">features</span>, <span class="va">betas</span><span class="op">)</span><span class="op">)</span>
<span class="va">feat_betas</span><span class="op">$</span><span class="va">betas</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">feat_betas</span><span class="op">$</span><span class="va">betas</span><span class="op">)</span>

<span class="va">feat_betas</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/desc.html">desc</a></span><span class="op">(</span><span class="va">betas</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/top_n.html">top_n</a></span><span class="op">(</span><span class="fl">20</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/kbl.html">kbl</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu"><a href="https://rdrr.io/pkg/kableExtra/man/kable_styling.html">kable_styling</a></span><span class="op">(</span>bootstrap_options <span class="op">=</span> <span class="st">"striped"</span><span class="op">)</span></code></pre></div>
<pre><code>## Selecting by betas</code></pre>
<div class="inline-table"><table class="table table-striped" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:left;">
features
</th>
<th style="text-align:right;">
betas
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
ig
</td>
<td style="text-align:right;">
8.961652
</td>
</tr>
<tr>
<td style="text-align:left;">
üé•
</td>
<td style="text-align:right;">
7.789170
</td>
</tr>
<tr>
<td style="text-align:left;">
diver
</td>
<td style="text-align:right;">
7.015280
</td>
</tr>
<tr>
<td style="text-align:left;">
alien-looking
</td>
<td style="text-align:right;">
6.054599
</td>
</tr>
<tr>
<td style="text-align:left;">
wwe
</td>
<td style="text-align:right;">
5.304742
</td>
</tr>
<tr>
<td style="text-align:left;">
cutest
</td>
<td style="text-align:right;">
5.304742
</td>
</tr>
<tr>
<td style="text-align:left;">
lad
</td>
<td style="text-align:right;">
5.012233
</td>
</tr>
<tr>
<td style="text-align:left;">
bargains
</td>
<td style="text-align:right;">
4.834996
</td>
</tr>
<tr>
<td style="text-align:left;">
partner‚Äôs
</td>
<td style="text-align:right;">
4.692453
</td>
</tr>
<tr>
<td style="text-align:left;">
ronaldo
</td>
<td style="text-align:right;">
4.495500
</td>
</tr>
<tr>
<td style="text-align:left;">
clever
</td>
<td style="text-align:right;">
4.351118
</td>
</tr>
<tr>
<td style="text-align:left;">
wheelchair
</td>
<td style="text-align:right;">
4.340551
</td>
</tr>
<tr>
<td style="text-align:left;">
mcguinness
</td>
<td style="text-align:right;">
4.340551
</td>
</tr>
<tr>
<td style="text-align:left;">
spider
</td>
<td style="text-align:right;">
4.192175
</td>
</tr>
<tr>
<td style="text-align:left;">
nails
</td>
<td style="text-align:right;">
4.192175
</td>
</tr>
<tr>
<td style="text-align:left;">
rides
</td>
<td style="text-align:right;">
3.950627
</td>
</tr>
<tr>
<td style="text-align:left;">
ghostly
</td>
<td style="text-align:right;">
3.950627
</td>
</tr>
<tr>
<td style="text-align:left;">
extensions
</td>
<td style="text-align:right;">
3.950627
</td>
</tr>
<tr>
<td style="text-align:left;">
corrie‚Äôs
</td>
<td style="text-align:right;">
3.950627
</td>
</tr>
<tr>
<td style="text-align:left;">
lion
</td>
<td style="text-align:right;">
3.857072
</td>
</tr>
</tbody>
</table></div>
<p>These words do seem to belong to more tabloid-style reportage, and include emojis relating to film, sports reporting on ‚Äúcristiano‚Äù as well as more colloquial terms like ‚Äúsaucy.‚Äù</p>
</div>
<div id="replicating-kaneko-et-al." class="section level2" number="20.5">
<h2>
<span class="header-section-number">20.5</span> Replicating Kaneko et al.<a class="anchor" aria-label="anchor" href="#replicating-kaneko-et-al."><i class="fas fa-link"></i></a>
</h2>
<p>This section adapts code from the replication data provided for <span class="citation">Kaneko, Asano, and Miwa (<a href="references-2.html#ref-kaneko_estimating_2021" role="doc-biblioref">2021</a>)</span> <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/EL3KYD">here</a>. We can access data from the first study by <span class="citation">Kaneko, Asano, and Miwa (<a href="references-2.html#ref-kaneko_estimating_2021" role="doc-biblioref">2021</a>)</span> in the following way.</p>
<div class="sourceCode" id="cb315"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">kaneko_dfm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/readRDS.html">readRDS</a></span><span class="op">(</span><span class="st">"data/wordscaling/study1_kaneko.rds"</span><span class="op">)</span></code></pre></div>
<p>If you‚Äôre working locally, you can download the <code>dfm</code> data with:</p>
<div class="sourceCode" id="cb316"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">kaneko_dfm</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/readRDS.html">readRDS</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/gzcon.html">gzcon</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/connections.html">url</a></span><span class="op">(</span><span class="st">"https://github.com/cjbarrie/CTA-ED/blob/main/data/wordscaling/study1_kaneko.rds?raw=true"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>This data is in the form a document-feature-matrix. We can first manipulate it in the same way as <span class="citation">Kaneko, Asano, and Miwa (<a href="references-2.html#ref-kaneko_estimating_2021" role="doc-biblioref">2021</a>)</span> by grouping at the level of newspaper and removing infrequent words.</p>
<div class="sourceCode" id="cb317"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="fu"><a href="https://quanteda.io/reference/docvars.html">docvars</a></span><span class="op">(</span><span class="va">kaneko_dfm</span>, <span class="st">"Newspaper"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## 
##       Asahi     Chugoku    Chunichi    Hokkaido      Kahoku    Mainichi      Nikkei Nishinippon 
##          38          24          47          46          18          26          13          27 
##      Sankei     Yomiuri 
##          14          30</code></pre>
<div class="sourceCode" id="cb319"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">## prepare the newspaper-level document-feature matrix</span>
<span class="co"># compress the document-feature matrix at the newspaper level</span>
<span class="va">kaneko_dfm_study1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/dfm_group.html">dfm_group</a></span><span class="op">(</span><span class="va">kaneko_dfm</span>, groups <span class="op">=</span> <span class="va">Newspaper</span><span class="op">)</span>
<span class="co"># remove words not used by two or more newspapers</span>
<span class="va">kaneko_dfm_study1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/dfm_trim.html">dfm_trim</a></span><span class="op">(</span><span class="va">kaneko_dfm_study1</span>, min_docfreq <span class="op">=</span> <span class="fl">2</span>, docfreq_type <span class="op">=</span> <span class="st">"count"</span><span class="op">)</span>

<span class="co">## size of the document-feature matrix</span>
<span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">kaneko_dfm_study1</span><span class="op">)</span></code></pre></div>
<pre><code>## [1]   10 4660</code></pre>
</div>
<div id="exercises-3" class="section level2" number="20.6">
<h2>
<span class="header-section-number">20.6</span> Exercises<a class="anchor" aria-label="anchor" href="#exercises-3"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li>Estimate a wordfish model for the <span class="citation">Kaneko, Asano, and Miwa (<a href="references-2.html#ref-kaneko_estimating_2021" role="doc-biblioref">2021</a>)</span> data</li>
<li>Visualize the results</li>
</ol>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="exercise-3-comparison-and-complexity.html"><span class="header-section-number">19</span> Exercise 3: Comparison and complexity</a></div>
<div class="next"><a href="exercise-5-unsupervised-learning-topic-models.html"><span class="header-section-number">21</span> Exercise 5: Unsupervised learning (topic models)</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#exercise-4-scaling-techniques"><span class="header-section-number">20</span> Exercise 4: Scaling techniques</a></li>
<li><a class="nav-link" href="#introduction-3"><span class="header-section-number">20.1</span> Introduction</a></li>
<li><a class="nav-link" href="#importing-data"><span class="header-section-number">20.2</span> Importing data</a></li>
<li><a class="nav-link" href="#construct-dfm-object"><span class="header-section-number">20.3</span> Construct dfm object</a></li>
<li><a class="nav-link" href="#estimate-wordfish-model"><span class="header-section-number">20.4</span> Estimate wordfish model</a></li>
<li><a class="nav-link" href="#replicating-kaneko-et-al."><span class="header-section-number">20.5</span> Replicating Kaneko et al.</a></li>
<li><a class="nav-link" href="#exercises-3"><span class="header-section-number">20.6</span> Exercises</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/cjbarrie/CTA-ED/blob/master/14-scaling.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/cjbarrie/CTA-ED/edit/master/14-scaling.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Computational Text Analysis</strong>" was written by Christopher Barrie. It was last built on 2023-02-06.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
